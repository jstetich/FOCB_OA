---
title: "Analysis of OA Data From FOCB"
author: "Curtis C. Bohlen, Casco Bay Estuary Partnership"
date: "7/15/2020"
output:
  github_document:
    toc: true
    fig_width: 7
    fig_height: 5
---

<img
  src="https://www.cascobayestuary.org/wp-content/uploads/2014/04/logo_sm.jpg"
  style="position:absolute;top:10px;right:50px;" />


```{r load_libraries}
library(tidyverse)
library(readxl)
library(readr)

library(GGally)
library(zoo)
library(lubridate)  # here, for the make_datetime() function

library(CBEPgraphics)
load_cbep_fonts()
```


# Load Data
## Establish Folder Reference
```{r folder_refs}
sibfldnm <- 'Original_Data'
parent   <- dirname(getwd())
sibling  <- file.path(parent,sibfldnm)

fn    <- 'CMS1 Data through 2019.xlsx'
fpath <- file.path(sibling,fn)

dir.create(file.path(getwd(), 'figures'), showWarnings = FALSE)
```

## Load The Data
We need to skip  the second row here, which is inconvenient largely because the
default "guess" of data contents for each column is based on the contents of
that first row of data.

A solution in an answer to this stack overflow questions
(https://stackoverflow.com/questions/51673418/how-to-skip-the-second-row-using-readxl)
suggests reading in the first row only to generate names, then skip the row of
names and the row of units, and read the "REAL" data.

Note that I round the timestamp on the data to the nearest hour.

### Primary Data
```{r load_data, warning = FALSE}
mynames <- read_excel(fpath, sheet = 'Sheet1', n_max = 1, col_names = FALSE)
mynames <- unname(unlist(mynames[1,]))  # flatten and simplify
mynames[2] <- 'datetime'               # 
mynames[4] <- 'depth'                   # Address non-standard names
mynames[8] <- 'pctsat'
mynames[18] <- 'omega_a'
mynames <- tolower(mynames)             # convert all to lower case

the_data <- read_excel(fpath, skip=2, col_names = FALSE)
names(the_data) <- mynames
rm(mynames)
```

```{r create_timestamp}
the_data <- the_data %>%
  select(-count, -time, -datetime)  %>%       # datetime and time contain the same data
  mutate(dt = make_datetime(year, month, day, hour, 0, tz = "America/New_York")) %>%
  rename(datetime = dt) %>%
  mutate(thedate  = as.Date(datetime),
         doy      = as.numeric(format(datetime, format = '%j')),
         tstamp   = paste0(year, '/', sprintf("%02d", month), '/',
                           sprintf("%02d", day), ' ', sprintf("%02d", hour)),
         Month = factor(month, labels = month.abb)) %>%
  arrange(datetime)                # Confirm that data are in chronological order

```

### CO2SYS Results
We ran CO2SYS in Python, principally to calculate estimated pH under the total pH scale.  Her we load it and use a left join by timestamp to add the data to the principal data set. 
```{r load_CO2SYS}
sibfldnm <- 'PyCO2SYS_Calc'
parent   <- dirname(getwd())
sibling  <- file.path(parent,sibfldnm)

fn    <- 'focbco2sys_out.csv'
fpath <- file.path(sibling,fn)


ph_tot_data <- read_csv(fpath, 
    col_types   = cols(month = col_integer(), 
        year    = col_integer(), 
        day     = col_integer(), 
        hour    = col_integer(), 
        temp    = col_number(), 
        sal     = col_number(), 
        pco2    = col_number(), 
        ph      = col_number(), 
        omega_a = col_number(), 
        omega_c = col_number(), 
        ta      = col_number(), 
        dic     = col_number(),
        ph_tot  = col_number())) %>%
  mutate(tstamp = paste0(year, '/', sprintf("%02d", month), '/',
                         sprintf("%02d", day), ' ', sprintf("%02d", hour))) %>%
  select(ph_tot, tstamp)
           
```

### Merge pH (Total Scale) data into primary data
Note this assumes there are no duplicate timestamps....
```{r merge_in pH data}

the_data <- the_data %>%
  left_join(ph_tot_data, by='tstamp') %>%
  select(-tstamp)
rm(ph_tot_data)
```


## Takehashi et al. 2002 Relationships
Here we follow a formula for calculating a "Temperature Corrected" pCO~2~, which is derived from methods in Takehashi et al. 2002. The "temperature corrected" version adjusts for the thermodynamic effect of temperature on pCO~2~.

> Takahashi, Taro & Sutherland, Stewart & Sweeney, Colm & Poisson, Alain &
> Metzl, Nicolas & Tilbrook, Bronte & Bates, Nicholas & Wanninkhof, Rik & Feely,
> Richard & Chris, Sabine & Olafsson, Jon & Nojiri, Yukihiro. (2002). Global
> sea-air CO2 flux based on climatological surface ocean pCO2, and seasonal
> biological and temperature effects. Deep Sea Research Part II: Topical Studies
> in Oceanography. 49. 1601-1622. 10.1016/S0967-0645(02)00003-6.

Takahashi et al. 2002 Used direct calculation of "temperature corrected" pCO~2~ as a surrogate for changes in CO~2~ concentration, and conversely, estimates of "expected" thermal pCO~2~, as estimates of the magnitude of the fluctuations in pCO~2~ one would expect to see due to temperature alone, if there were no changes in [CO~2~].

The Takehashi et al. 2002 equations are as follows:

#### "Expected pCO~2~" at Observed Temperature
$$(pCO_{2} \textrm{ at }T_{obs}) = (pCO_{2})_{obs} \times exp(0.0423(T_{obs}- T_{mean})$$

#### "Temperature Corrected" pCO~2~
$$(pCO_{2} \textrm{ at }T_{mean}) = (pCO_{2})_{obs} \times exp(0.0423(T_{mean}- T_{obs})$$

### Calculations
Here we calculate the "temperature corrected" time series as calculated in Takehashi et al. "Temperature Corrected" pCO~2~ value ("co2_corr") provides a trace of changes in pCO~2~ that "would have happened" in the absence of temperature changes.  These reflect changes in the concentration of CO~2~, which reflect a combination of biology and diffusion of CO~2~ between ocean and atmosphere and advection past the sensor by tides and currents. Here we adjust pCO~2~ to a "standard temperature" of 12 degrees C.  This is slightly warmer than  the observed annual average temperature We use 2 degrees C only for consistency with analysis of the CBEP / UNH data. 

```{r calc_pco2_corr}
t_ref = 12
the_data <- the_data %>%
  mutate(pco2_corr =  pco2*exp(0.0423*(t_ref-temperature))) %>%
  select(c(16, 17, 11, 10, 9, 19, 12,  18, 1:5, 7,  6, 20, 8, 21, 13:15))  # reorder for convenience
rm(t_ref)
```

## Create Long Form Data
```{r long_data}
long_data <- the_data %>%
  pivot_longer(cols= depth:omega_a, names_to='Parameter', values_to = 'Value') %>%
  mutate(Parameter = factor(Parameter,
                            levels = c('depth',
                                       'temperature',
                                       'salinity',
                                       'do',
                                       'pctsat',
                                       'chl',
                                       'ph',
                                       'ph_tot',
                                       'pco2',
                                       'pco2_corr',
                                       'ta',
                                       'dic',
                                       'omega-a')))
```


## Create Daily Data Summaries
```{r daily_data}
daily_data <- the_data %>%
  select(-hour, -year, -month, -day, -doy) %>%         # Will recalculate these 
  group_by(thedate) %>%
  summarise_at(c("temperature", "salinity", "do", "pctsat", "chl", "ph", "ph_tot",
                 "pco2", "pco2_corr", "ta", "dic", 'omega_a'),
               c(a    = function(x) mean(x, na.rm=TRUE),
                 m    = function(x) median(x, na.rm=TRUE),
                 r    = function(x) {suppressWarnings(max(x, na.rm=TRUE) -
                                                        min(x, na.rm=TRUE))},
                iqr  = function(x) IQR(x, na.rm=TRUE),
                p80r = function(x) {as.numeric(quantile(x, 0.90, na.rm=TRUE) -
                       quantile(x, 0.10, na.rm=TRUE))})) %>%
  mutate(year = as.numeric(format(thedate, format = '%Y')),
         month  = as.numeric(format(thedate, format = '%m')),
         dd   = as.numeric(format(thedate, format = '%d')),
         doy  = as.numeric(format(thedate, format = '%j')),
         Month = factor(month, levels=1:12, labels = month.abb)
         )
```


## Calculate Diurnal Deviations
We calculate hourly deviation from daily averages for the principal OA measures. This allows us to look at diurnal patterns.
```{r hourly_deviations}
diurnal_data <- the_data %>%
  group_by(thedate) %>%
  
  # Calculate sample sizes for each day.
  mutate(pco2_n      = sum(! is.na(pco2)),
         pco2_corr_n = sum(! is.na(pco2_corr)),
         ph_n        = sum(! is.na(ph)),
         ph_tot_n    = sum(! is.na(ph_tot)),
         omega_n     = sum(! is.na(omega_a))) %>%
  
  # Calculate centered but not scaled values, day by day.
  mutate(pco2_res      = scale(pco2, scale = FALSE),
         pco2_corr_res = scale(pco2_corr, scale = FALSE),
         ph_res        = scale(ph, scale = FALSE),
         ph_tot_res    = scale(ph_tot, scale = FALSE),
         omega_res     = scale(omega_a, scale=FALSE)) %>%
  ungroup() %>%
  
  # Replace data from any days with less than 20 hours of data with NA
  mutate(pco2_res      = ifelse(pco2_n>=20, pco2_res, NA),
         pco2_corr_res = ifelse(pco2_corr_n>=20, pco2_corr_res, NA),
         ph_res        = ifelse(ph_n>=20, ph_res, NA),
         ph_tot_res    = ifelse(ph_tot_n>=20, ph_res, NA),
         omega_res     = ifelse(omega_n>=20, ph_res, NA)) %>%
  
  # Delete the daily sample size variables
  select(-contains("_n")) %>%
  mutate(Month = factor(month, levels = 1:12, labels=month.abb))
```


# Exploratory Graphics
```{r pairs_plot_1, warning=FALSE, cache = TRUE}
the_data %>% ggpairs(c(10:12, 13:14), progress=FALSE)
```
What jumps out most strongly is the negative association between temperature and DO. Most of the negative association between DO and temperature vanishes when looking at percent saturation.  
Temperature show strong bimodal distribution, presumably because of winter and summer temperature regimes.
DO shows weak bimodal structure, but percent saturation does not.


```{r pairs_plot_2, warning=FALSE, cache = TRUE}
the_data %>% ggpairs(c(10:12, 15:18), progress=FALSE)
```
Mutual temperature dependence of DO and pCO~2~ means those two variables are negatively correlated.  WEAK negative association remains even after temperature correction, so this is not just a thermodynamic relationship.  (Don't trust statistical significance as observations have very high autocorrelation.)

Negative pH PCO2 relationships are fairly robust here. They are stronger before temperature correction.

There are a few wonky observations.  They look like high pCO2, moderate low salinity in moderately cool temperatures.  I bet they are all a big storm event.....


```{r pairs_plot_3, warning=FALSE, cache = TRUE}
the_data %>% ggpairs(c(10:12, 17:21), progress=FALSE)
```
Calculates total alkalinity and dissolved inorganic carbon are nearly measuring the same thing -- no surprise in sea water.

Don't believe the measures of statistical significance here, as the implied models do not account for very high autocorrelations.  Checking these correlations will involve developing GAMM models.

# Summary Statistics
# Entire Data Set
This is legacy code. It would be easier today to develop this directly in the tidyverse.
```{r summary_stats}
the.mins     <- sapply(the_data[9:21], min, na.rm=TRUE)
the.medians  <- sapply(the_data[9:21], median, na.rm=TRUE)
the.means    <- sapply(the_data[9:21], mean, na.rm=TRUE)
the.maxes    <- sapply(the_data[9:21], max, na.rm=TRUE)
the.SDs  <-   sapply(the_data[9:21], sd, na.rm=TRUE)
the.samplesizes <-  sapply(the_data[9:21], function(x) sum(! is.na(x)) )
result   <-  cbind(the.mins, the.medians, the.means, the.maxes, the.SDs, the.samplesizes)
colnames(result) <- c('Minimum', 'Median', 'Mean', 'Maximum', 'Std. Deviation', 'Observations')
rownames(result) <- c('Depth',
                      'Temperature',
                      'Salinity',
                      'DO (mg/l)',
                      'Percent Saturation',
                      'Chlorophyll-a',
                      'pH (NMS)',
                      'pH (Total, calculated)',
                      'pCO2',
                      'pCO2_corr',
                      'Total Alkalinity',
                      'Dissolved Inorganic Carbon',
                      'Omega Aragonite'
                      )
knitr::kable(result, digits = c(1,1,2,1,3,0))
write.csv(result, 'summarystats_OA_FOCB.csv')
```

```{r cleanup, echo=FALSE}
rm(the.mins, the.means, the.medians, the.maxes, the.SDs, the.samplesizes, result)
```

## Omega Aragonite Observations and Percentage Below Levels of Concern
```{r levels_of_concern_1}
below1.5 <- sum(the_data$omega_a<1.5, na.rm=TRUE)
below1.0 <- sum(the_data$omega_a<1.0, na.rm=TRUE)
TotObs   <- sum(! is.na(the_data$omega_a))
pctbelow1.5 <- below1.5/TotObs
pctbelow1.0 <- below1.0/TotObs

res <- unlist( list(`Count Below 1.0` = below1.0, `Count Below 1.5` = below1.5,
      `Observations` = TotObs,
      `Percent Below 1.0` = pctbelow1.0,
      `Percent Below 1.5` =pctbelow1.5))
rm(below1.0, below1.5, TotObs, pctbelow1.0, pctbelow1.5)
knitr::kable(t(res), digits = c(0,0,0,3,3))
```

## Daily Omega Aragonite (medians) Observations and and Percentage Below Levels of Concern
```{r daily_levels_of_concern}
below1.5 <- sum(daily_data$omega_a_m<1.5, na.rm=TRUE)
below1.0 <- sum(daily_data$omega_a_m<1.0, na.rm=TRUE)
TotObs   <- sum(! is.na(daily_data$omega_a_m))
pctbelow1.5 <- below1.5/TotObs
pctbelow1.0 <- below1.0/TotObs

res <- unlist(list(`Count Below 1.0` = below1.0, `Count Below 1.5` = below1.5,
      `Observations` = TotObs,
      `Percent Below 1.0` = pctbelow1.0,
      `Percent Below 1.5` =pctbelow1.5))
rm(below1.0, below1.5, TotObs, pctbelow1.0, pctbelow1.5)
knitr::kable(t(res), digits = c(0,0,0,3,3))
```

## Monthly Summary Statistics
This is means **across** years.  This is NOT the same as an estimated monthly average, adjusted for year to year variation, imbalances in time of day data was collected, etc.  For that, we would need to estimate marginal means from a GAMM. We do not pursue that idea in this notebook.  

```{r monthly_stats}
monthly_tbl <- the_data %>%
  select(datetime, year, Month, temperature, salinity, do, pctsat, chl, ph, ph_tot, pco2, pco2_corr, omega_a) %>%

  pivot_longer(temperature:omega_a, names_to = 'parameter',
               values_to = 'value') %>%
  group_by(Month, parameter) %>%
  summarise(
    avg    = round(mean(value, na.rm = TRUE), 2),
    median = round(median(value, na.rm = TRUE), 2),
    sd     = round(sd(value, na.rm = TRUE), 3),
    count  = sum(!is.na(value))
  ) %>%
  pivot_longer(cols = c('avg', 'median', 'sd', 'count'),
               names_to = 'label') %>%
  pivot_wider(id_cols = c(parameter, label), names_from=Month) 
knitr::kable(monthly_tbl)
write_csv(monthly_tbl, 'Monthly_summaries_OA_FOCB.csv')
```


# Base Graphics

## Constants for Axis Labels
```{r axis_setup}
monthlengths <-  c(31,28,31, 30,31,30,31,31,30,31,30,31)
cutpoints    <- c(0, cumsum(monthlengths)[1:12])
monthlabs    <- c(month.abb,'')
```

## Seasonal Profiles
These graphs combine data from multiple years to generate a picture of seasonal conditions across multiple years.  Since data coverage is inconsistent year to year, data for some times of year are derived from just one or two years, which could bias the results.  

### Raw pCO2
```{r pc02_Raw_by_doy,fig.width = 7, fig.height = 5}
plt <- ggplot(the_data, aes(doy, pco2)) + geom_point(aes(color = factor(year)), alpha = 0.1) +
  
  geom_hline(aes(yintercept = 400), lty = 'solid', color = 'gray') +
  annotate('text', x=0, y=430, label= expression(pCO[2*(cor)]~'='~ 400), hjust = 0, size=3) +
  
  xlab('') +
  ylab(expression (pCO[2]~(mu*Atm))) +
  scale_color_manual(values=cbep_colors()[c(3,2,5,4)], name='Year') +
  scale_x_continuous(breaks = cutpoints, labels = monthlabs) +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  theme_cbep() +
  theme(axis.text.x=element_text(angle=90, vjust = 1.5))
plt
#ggsave('figures/pco2RawSeasonal_focb.png', type = 'cairo', width = 7, height = 5)
ggsave('figures/pco2RawSeasonal_focb.pdf', device=cairo_pdf, width = 7, height = 5)
```


### Temperature Corrected pCO2
It's not technically OK to show a reference line on a figure with temperature-corrected pCO2.  The equilibrium between [co~2~] and fugacity is temperature dependent.

```{r pc02_by_doy,fig.width = 7, fig.height = 5}
plt <- ggplot(the_data, aes(doy, pco2_corr)) + geom_point(aes(color = factor(year)), alpha = 0.1) +
  
  # geom_hline(aes(yintercept = 400), lty = 'dotted', color = 'gray') +
  # annotate('text', x=365, y=370, label= expression(pCO[2*(cor)]~'='~ 400), hjust=1, size=3) +
  
  xlab('') +
  ylab(expression (pCO[2*(cor)]~(mu*Atm))) +
  scale_color_manual(values=cbep_colors()[c(3,2,5,4)], name='Year') +
  scale_x_continuous(breaks = cutpoints, labels = monthlabs) +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  theme_cbep() +
  theme(axis.text.x=element_text(angle=90, vjust = 1.5))
plt
#ggsave('figures/pco2Seasonal_focb.png', type = 'cairo', width = 7, height = 5)
ggsave('figures/pco2Seasonal_focb.pdf', device=cairo_pdf, width = 7, height = 5)
```
This shows much less obvious seasonality than the CBEP / UNH site.

### Both Raw and Corrected pco~2~ on One Graph.
```{r pco2_comparison, fig.height = 2, fig.width = 3}
plt  <- long_data %>% filter(Parameter %in% c('pco2', 'pco2_corr')) %>%
  
  mutate(Parameter = factor(Parameter, levels = c('pco2', 'pco2_corr'),
                            labels = c('Observed',
                                       'Temp. Corrected'))) %>% 
  
  ggplot(aes(x=doy, y=Value, alpha=Parameter)) + geom_line(aes(color = Parameter)) +
 
  scale_alpha_discrete(range = c(0.25, 1), name = '') +
  scale_x_continuous(breaks = cutpoints, labels = monthlabs) + 
  scale_color_manual(values=cbep_colors2(), name='') +

  xlab('') +
  ylab(expression (pCO[2]~(mu*Atm))) +

  #guides(colour = guide_legend(override.aes = list(alpha = c(0.25, 1)))) +
  
  theme_cbep(base_size = 10) +
  theme(axis.text.x=element_text(angle=90, vjust = 1.5)) +
  theme(legend.position= c(.3, .8))
plt

#ggsave('figures/pco2compare_focb.png', type = 'cairo', width = 3, height = 2)
ggsave('figures/pco2compare_focb.pdf', device=cairo_pdf, width = 3, height = 2)

```

### pH (Total Scale)
```{r ph_by_doy,fig.width = 7, fig.height = 5}
plt <- ggplot(the_data, aes(doy, ph_tot)) + geom_point(aes(color = factor(year)),alpha = 0.05) +
  xlab('') +
  ylab('pH') +
  scale_color_manual(values=cbep_colors()[c(3,2,5,4)], name='Year') +
  scale_x_continuous(breaks = cutpoints, labels = monthlabs) +

  scale_y_continuous(limits = c(7.5, 8.5), breaks = c(7.5, 7.75, 8.0, 8.25, 8.5)) +
  
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  theme_cbep() +
  theme(axis.text.x=element_text(angle=90, vjust = 1.5))
plt
#ggsave('figures/phSeasonal_focb.png', type = 'cairo', width = 7, height = 5)
ggsave('figures/phSeasonal_focb.pdf', device=cairo_pdf, width = 7, height = 5)
```

### Aragonite Saturation State
```{r omega_by_doy, fig.width = 7, fig.height = 5}
plt <- ggplot(the_data, aes(doy, omega_a)) + geom_point(aes(color = factor(year)), alpha = 0.1) +
  
  # geom_hline(aes(yintercept = 1.5), lty = 'solid', color = 'gray') +
  # geom_text(aes(x=0, y=1.4, label= 'Omega = 1.5', hjust = 0), size=3) +
  
  geom_hline(aes(yintercept = 1), lty = 'solid', color = 'gray') +
  geom_text(aes(x=0, y=1.1, label= 'Omega = 1.0', hjust = 0), size=3) +
  
  
  xlab('') +
  ylab(expression(Omega[a])) +
  
  scale_color_manual(values=cbep_colors()[c(3,2,5,4)], name='Year') +
  scale_x_continuous(breaks = cutpoints, labels = monthlabs) +
  
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  
  theme_cbep() +
  theme(axis.text.x=element_text(angle=90, vjust = 1.5))
  
plt
#ggsave('figures/omegaSeasonal_focb.png', type = 'cairo', width = 7, height = 5)
ggsave('figures/omegaSeasonal_focb.pdf', device=cairo_pdf, width = 7, height = 5)

```

# Daily Patterns
```{r reorganize data}
long_diurnal_data <- diurnal_data %>% select(-c(9:16)) %>%  # Drop all raw observations; retain diurnal residuals
                                               
  pivot_longer(contains("_res"), names_to='metric') %>%
  mutate(metric= sub("_res", "", metric))       #simplify names
```


## Diurnal Trendlines
Here we display trendlines derived from GAM models by month.  As noted above, these models are likely to slightly overfit the trends.

Notice that the selection of the dimension of the periodic basis of the smooths in the GAM (signaled in k=6) is essentially selected here by eye to create a visual balance between simplicity and complexity.  The default here probably over-fits, as described above.  We explore the implied GAM (and related GAMM) further in the another R Notebook in the "Analysis" folder.

```{r combined_plot, fig.width = 8, fig.height = 5}
labs <- c(expression(paste(pCO[2*(cor)], ' (', mu, 'Atm)')), 'pH')
names(labs) <- unique(long_diurnal_data$metric)[c(2,4)]

tmp <- long_diurnal_data %>%
  filter( metric %in% c('pco2_corr', 'ph_tot')) %>%
  mutate(metric = factor(metric, levels = names(labs), labels = labs))

plt <-
  ggplot(tmp, aes(hour,value, color = Month)) +
  geom_smooth(aes(color = Month), method = "gam",
              formula = y~s(x, bs='cc', k=6), se=FALSE) +

  theme_cbep() +
  theme(panel.spacing = unit(2, "lines")) +
  
  xlab('Hour of the Day') +
  ylab('Difference from Daily Average') +
  facet_wrap(~metric, nrow=1, scales='free_y',
                   labeller = label_parsed ) +
  scale_color_discrete(name = "Month") + 
  scale_x_continuous(breaks = c(0,6,12,18,24)) #+
  #ggtitle('Daily Fluctuations')
plt
ggsave('figures/dailyco2andphbymonth_focb.pdf', device = cairo_pdf, width = 8, height = 5)
#ggsave('figures/dailyco2andphbymonth_focb.png', type = 'cairo', width = 8, height = 5)
```

## Corrected pCO2 Graph
```{r pco2_figure, fig.width = 4, fig.height = 4, warning=FALSE}
plt <- diurnal_data %>%
  ggplot(aes(hour,pco2_corr_res)) +
  geom_smooth(aes(color=Month), method = "gam",
              formula = y~s(x, bs='cc', k=6), se=FALSE, lwd=0.75) +
  # annotate(geom = "text", label = expression(atop("Temperature", "Corrected"~pCO[2])),
  #          x = 24, y = 30,
  #          color = "black", hjust=1, size = 4) +
  theme_cbep(base_size = 12) +
  xlab('Hour of Day') +
  ylab(expression (atop(pCO[2*(cor)]~(mu*Atm), Difference~From~Daily~Average))) +
  scale_color_discrete(name = "Month") + 
  theme(legend.key.width = unit(0.25,"in"),
        legend.text      = element_text(size = 10)
        ) +
  scale_x_continuous(breaks = c(0,6,12,18,24)) #+
  #ggtitle(expression(Daily~pCO[2]))
plt
ggsave('figures/dailyCO2bymonth_focb.pdf', device=cairo_pdf, width = 4, height = 4)
#ggsave('figures/dailyCO2bymonth_focb.png', type='cairo', width = 4, height = 4)
```

## pH Graph
```{r phfigure, fig.width = 4, fig.height = 4, warning=FALSE}
plt <- diurnal_data %>%
  ggplot(aes(hour,ph_res)) +
  geom_smooth(aes(color=Month), method = "gam",
              formula = y~s(x, bs='cc', k=6), se=FALSE) +
  theme_cbep(base_size = 12) +
  theme(legend.key.width = unit(0.25,"in"),
        legend.text      = element_text(size = 10)
        ) +
  xlab('Hour of Day') +
  ylab(expression (atop(pH, Difference~From~Daily~Average))) +
  scale_color_discrete(name = "Month") + 
  scale_linetype_discrete(name = "Month") + 
  theme(legend.key.width=unit(0.25,"in")) +
  scale_x_continuous(breaks = c(0,6,12,18,24)) #+
  #ggtitle(expression(Daily~pH))
plt
ggsave('figures/dailyphbymonth_focb.pdf', device=cairo_pdf, width = 4, height = 4)
#ggsave('figures/dailyphbymonth_focb.png', type='cairo', width = 4, height = 4)
```

